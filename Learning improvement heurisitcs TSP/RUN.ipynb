{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "import json\n",
    "import pprint as pp\n",
    "from options import get_options\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboard_logger import Logger as TbLogger\n",
    "\n",
    "from critic_network import CriticNetwork\n",
    "from options import get_options\n",
    "from train import train_epoch, get_inner_model   ##########  no need for validate now\n",
    "from baselines import CriticBaseline\n",
    "from attention_model import AttentionModel\n",
    "from utils import torch_load_cpu, load_model, maybe_cuda_model, load_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline': 'critic',\n",
      " 'batch_size': 10,\n",
      " 'checkpoint_epochs': 1,\n",
      " 'embedding_dim': 128,\n",
      " 'epoch_size': 100,\n",
      " 'epoch_start': 0,\n",
      " 'eval_batch_size': 200,\n",
      " 'eval_only': False,\n",
      " 'graph_size': 50,\n",
      " 'hidden_dim': 128,\n",
      " 'lambda': 0.8,\n",
      " 'load_path': None,\n",
      " 'log_dir': 'logs',\n",
      " 'log_step': 50,\n",
      " 'lr_critic': 0.0001,\n",
      " 'lr_decay': 0.99,\n",
      " 'lr_model': 0.0001,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'n_encode_layers': 3,\n",
      " 'n_epochs': 100,\n",
      " 'no_cuda': False,\n",
      " 'no_progress_bar': False,\n",
      " 'no_tensorboard': False,\n",
      " 'normalization': 'batch',\n",
      " 'output_dir': 'outputs',\n",
      " 'problem': 'tsp',\n",
      " 'resume': None,\n",
      " 'run_name': 'run',\n",
      " 'save_dir': 'outputs\\\\tsp_50\\\\run',\n",
      " 'seed': 1234,\n",
      " 'steps': 10,\n",
      " 'tanh_clipping': 10.0,\n",
      " 'use_cuda': True,\n",
      " 'val_dataset': None,\n",
      " 'val_size': 2000}\n",
      "Start train epoch 0, lr=0.0001 for run run\n",
      "Start train epoch 0, lr=0.0001 for run run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\WUYAOXIN\\AppData\\Local\\Continuum\\miniconda3\\envs\\deeplearn_course\\lib\\site-packages\\torch\\nn\\functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "D:\\CE7454_2018\\Learning local search_TSP_07 (50best_version) (1024)\\train.py:170: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  for group in param_groups\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [06:09<00:00, 36.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, took 00:06:09 s\n",
      "Saving model and state...\n",
      "Validating...\n",
      "Test, took 00:01:59 s\n",
      "Improving: 4.934609889984131 +- 0.15752926468849182\n",
      "Best Improving: 8.985796928405762 +- 0.1288522183895111\n",
      "Best solutions: 17.050809860229492 +- 0.09012404829263687\n",
      "Start train epoch 1, lr=0.0001 for run run\n",
      "Start train epoch 1, lr=9.900000000000001e-05 for run run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [01:13<04:53, 36.74s/it]"
     ]
    }
   ],
   "source": [
    "pp.pprint(vars(opts))\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(opts.seed)\n",
    "\n",
    "# Optionally configure tensorboard\n",
    "tb_logger = None\n",
    "if not opts.no_tensorboard:\n",
    "    tb_logger = TbLogger(os.path.join(opts.log_dir, \"{}_{}\".format(opts.problem, opts.graph_size), opts.run_name))\n",
    "\n",
    "\n",
    "os.makedirs(opts.save_dir)\n",
    "with open(os.path.join(opts.save_dir, \"args.json\"), 'w') as f:\n",
    "    json.dump(vars(opts), f, indent=True)\n",
    "\n",
    "problem = load_problem(opts.problem)\n",
    "\n",
    "# Load data from load_path\n",
    "load_data = {}\n",
    "assert opts.load_path is None or opts.resume is None, \"Only one of load path and resume can be given\"\n",
    "load_path = opts.load_path if opts.load_path is not None else opts.resume\n",
    "if load_path is not None:\n",
    "    print('  [*] Loading data from {}'.format(load_path))\n",
    "    load_data = load_data = torch_load_cpu(load_path)\n",
    "\n",
    "# Initialize model\n",
    "model_class = AttentionModel\n",
    "model = maybe_cuda_model(\n",
    "    model_class(\n",
    "        opts.embedding_dim,\n",
    "        opts.hidden_dim,\n",
    "        problem,\n",
    "        n_encode_layers=opts.n_encode_layers,\n",
    "        mask_inner=True,\n",
    "        mask_logits=True,\n",
    "        normalization=opts.normalization,\n",
    "        tanh_clipping=opts.tanh_clipping\n",
    "    ),\n",
    "    opts.use_cuda\n",
    ")\n",
    "\n",
    "# Overwrite model parameters by parameters to load\n",
    "model_ = get_inner_model(model)\n",
    "model_.load_state_dict({**model_.state_dict(), **load_data.get('model', {})})\n",
    "\n",
    "# Initialize baseline\n",
    "baseline = CriticBaseline(\n",
    "            maybe_cuda_model(\n",
    "                CriticNetwork(\n",
    "                    2,\n",
    "                    opts.embedding_dim,\n",
    "                    opts.hidden_dim,\n",
    "                    opts.n_encode_layers,\n",
    "                    opts.normalization\n",
    "                ),\n",
    "                opts.use_cuda\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Load baseline from data, make sure script is called with same type of baseline\n",
    "if 'baseline' in load_data:\n",
    "    baseline.load_state_dict(load_data['baseline'])\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(\n",
    "    [{'params': model.parameters(), 'lr': opts.lr_model}]\n",
    "    + (\n",
    "        [{'params': baseline.get_learnable_parameters(), 'lr': opts.lr_critic}]\n",
    "        if len(baseline.get_learnable_parameters()) > 0\n",
    "        else []\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load optimizer state\n",
    "if 'optimizer' in load_data:\n",
    "    optimizer.load_state_dict(load_data['optimizer'])\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            # if isinstance(v, torch.Tensor):\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.cuda()\n",
    "\n",
    "# Initialize learning rate scheduler, decay by lr_decay once per epoch!\n",
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: opts.lr_decay ** epoch)\n",
    "\n",
    "# Start the actual training loop\n",
    "# val_dataset = problem.make_dataset(size=opts.graph_size, num_samples=opts.val_size, filename=opts.val_dataset)\n",
    "# torch.save(val_dataset,'myval_100.pt')\n",
    "\n",
    "val_dataset = torch.load('test50.pt')\n",
    "val_dataset = val_dataset[0:200]\n",
    "\n",
    "if opts.resume:\n",
    "    epoch_resume = int(os.path.splitext(os.path.split(opts.resume)[-1])[0].split(\"-\")[1])\n",
    "\n",
    "    torch.set_rng_state(load_data['rng_state'])\n",
    "    if opts.use_cuda:\n",
    "        torch.cuda.set_rng_state_all(load_data['cuda_rng_state'])\n",
    "    # Set the random states\n",
    "    # Dumping of state was done before epoch callback, so do that now (model is loaded)\n",
    "    baseline.epoch_callback(model, epoch_resume)\n",
    "    print(\"Resuming after {}\".format(epoch_resume))\n",
    "    opts.epoch_start = epoch_resume + 1\n",
    "\n",
    "if opts.eval_only:\n",
    "    validate(model, val_dataset, opts)\n",
    "else:\n",
    "    for epoch in range(opts.epoch_start, opts.epoch_start + opts.n_epochs):\n",
    "        train_epoch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            baseline,\n",
    "            lr_scheduler,\n",
    "            epoch,\n",
    "            val_dataset,\n",
    "            problem,\n",
    "            tb_logger,\n",
    "            opts\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
